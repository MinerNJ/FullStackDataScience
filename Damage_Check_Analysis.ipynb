{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"model\"           : \"vgg16\",\n",
    "    \"weights\"         : \"imagenet\",\n",
    "    \"features_path\"   : \"C:\\\\Users\\\\nickm\\\\PythonProjects\\\\FullStackDataScience\\\\car_damage_check\\\\features.h5\",\n",
    "    \"labels_path\"     : \"C:\\\\Users\\\\nickm\\\\PythonProjects\\\\FullStackDataScience\\\\car_damage_check\\\\labels.h5\",\n",
    "    \"classifier_path\" : \"C:\\\\Users\\\\nickm\\\\PythonProjects\\\\FullStackDataScience\\\\car_damage_check\\\\classifier.pickle\",\n",
    "    \"model_path\"      : \"C:\\\\Users\\\\nickm\\\\PythonProjects\\\\FullStackDataScience\\\\car_damage_check\\\\model\",\n",
    "    \n",
    "    \"test_size\"       : 0.20,\n",
    "    \"seed\"            : 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filter warnings\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##config variables\n",
    "\n",
    "test_size = config[\"test_size\"]\n",
    "seed = config[\"seed\"]\n",
    "features_path = config[\"features_path\"]\n",
    "labels_path = config[\"labels_path\"]\n",
    "classifier_path = config[\"classifier_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import features and labels\n",
    "\n",
    "h5f_data = h5py.File(features_path, 'r')\n",
    "h5f_label = h5py.File(labels_path, 'r')\n",
    "\n",
    "features_string = h5f_data['dataset_1']\n",
    "labels_string = h5f_label['dataset_1']\n",
    "\n",
    "features = np.array(features_string)\n",
    "labels = np.array(labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (1840, 4096)\n",
      "[INFO] labels shape: (1840,)\n",
      "[INFO] training started...\n",
      "[INFO] spltting data into training and test sets...\n",
      "[INFO] train data   : (1472, 4096)\n",
      "[INFO] test data    : (368, 4096)\n",
      "[INFO] train labels : (1472,)\n",
      "[INFO] test labels  : (368,)\n"
     ]
    }
   ],
   "source": [
    "##verify the shape of features and labels\n",
    "print(\"[INFO] features shape: {}\".format(features.shape))\n",
    "print(\"[INFO] labels shape: {}\".format(labels.shape))\n",
    "\n",
    "print(\"[INFO] training started...\")\n",
    "\n",
    "#splitting the data into training and test sets\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),\n",
    "                                                                 np.array(labels),\n",
    "                                                                 test_size=test_size,\n",
    "                                                                 random_state=seed)\n",
    "\n",
    "print(\"[INFO] spltting data into training and test sets...\")\n",
    "print(\"[INFO] train data   : {}\".format(trainData.shape))\n",
    "print(\"[INFO] test data    : {}\".format(testData.shape))\n",
    "print(\"[INFO] train labels : {}\".format(trainLabels.shape))\n",
    "print(\"[INFO] test labels  : {}\".format(testLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=9, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evalute the model on the test data\n",
    "preds = model.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model...\n"
     ]
    }
   ],
   "source": [
    "##dump classifier to file\n",
    "\n",
    "print(\"[INFO] saving model...\")\n",
    "pickle.dump(model, open(classifier_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[171,  15],\n",
       "       [ 14, 168]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print(\"[INFO] confusion matrix\")\n",
    "\n",
    "#show confusion matrix\n",
    "cm = confusion_matrix(testLabels, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.11956521739131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Accuracy of model 92%!\n",
    "accuracy = ((368 - (15+14))/368)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-81d98bd65069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m sns.heatmap(cm,\n\u001b[0m\u001b[0;32m      2\u001b[0m            \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m            cmap=\"Set2\")\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.heatmap(cm,\n",
    "           annot=True,\n",
    "           cmap=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This logistic regression classifier is a model with 92% accuracy at telling the\n",
    "#difference between a damaged and undamaged car without having seen it before."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
